{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **feature encoding for activities**"
      ],
      "metadata": {
        "id": "fuaYLp-SZzk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode_activities(df, activities_file):\n",
        "    # Read activities from file\n",
        "    with open(activities_file, 'r') as f:\n",
        "        activities = [line.strip() for line in f]\n",
        "\n",
        "    # Create label encoder\n",
        "    le = LabelEncoder()\n",
        "    le.fit(activities)\n",
        "\n",
        "    # Get activity columns\n",
        "    activity_cols = [col for col in df.columns if col.startswith('activity-')]\n",
        "\n",
        "    # Encode each activity column\n",
        "    for col in activity_cols:\n",
        "        # Replace empty strings with None\n",
        "        df[col] = df[col].replace('', None)\n",
        "        # Only encode non-null values\n",
        "        mask = df[col].notnull()\n",
        "        df.loc[mask, col] = le.transform(df.loc[mask, col])\n",
        "        # Convert to float to match other numerical columns\n",
        "        df[col] = df[col].astype(float)\n",
        "\n",
        "    return df, dict(zip(le.classes_, le.transform(le.classes_)))\n"
      ],
      "metadata": {
        "id": "CCLkYLJhZueG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, activity_mapping = encode_activities(df, '/content/drive/MyDrive/AML_Project/activities.txt')\n",
        "print(\"Activity mapping:\", activity_mapping)"
      ],
      "metadata": {
        "id": "ymWXeXbWZ3wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature aggregation**"
      ],
      "metadata": {
        "id": "GUx6R-9_Z9tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def process_time_series(df, is_test=False):\n",
        "    def extract_hour(col):\n",
        "        if '-' in col:\n",
        "            return int(col.split('-')[1].split(':')[0])\n",
        "        return 0\n",
        "\n",
        "    def aggregate_by_category(df, category, agg_func):\n",
        "        cols = [col for col in df.columns if col.startswith(f\"{category}-\")]\n",
        "        if not cols:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        hour_groups = {}\n",
        "        for col in cols:\n",
        "            hour = extract_hour(col)\n",
        "            if hour not in hour_groups:\n",
        "                hour_groups[hour] = []\n",
        "            hour_groups[hour].append(col)\n",
        "\n",
        "        results = {}\n",
        "        for hour, hour_cols in hour_groups.items():\n",
        "            data = df[hour_cols]\n",
        "\n",
        "            if category == 'activity':\n",
        "                filled_data = data.fillna(-1)\n",
        "                non_null_mean = filled_data[filled_data != -1].mean(axis=1)\n",
        "                results[f\"{category}_hour_{hour}\"] = non_null_mean\n",
        "            else:\n",
        "                if agg_func == 'sum':\n",
        "                    results[f\"{category}_hour_{hour}\"] = data.sum(axis=1)\n",
        "                elif agg_func == 'mean':\n",
        "                    results[f\"{category}_hour_{hour}\"] = data.mean(axis=1)\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    # Adjust preserved columns based on whether it's test data\n",
        "    preserved_cols = ['id', 'p_num']\n",
        "    if not is_test:\n",
        "        preserved_cols.append('bg+1:00')\n",
        "\n",
        "    processed_dfs = [df[preserved_cols]]\n",
        "\n",
        "    aggregations = {\n",
        "        'bg': 'mean',\n",
        "        'insulin': 'sum',\n",
        "        'carbs': 'sum',\n",
        "        'hr': 'mean',\n",
        "        'steps': 'sum',\n",
        "        'cals': 'sum',\n",
        "        'activity': 'mean'\n",
        "    }\n",
        "\n",
        "    for category, agg_func in aggregations.items():\n",
        "        category_data = aggregate_by_category(df, category, agg_func)\n",
        "        if not category_data.empty:\n",
        "            processed_dfs.append(category_data)\n",
        "\n",
        "    return pd.concat(processed_dfs, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "n_-zfD9taDKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost**"
      ],
      "metadata": {
        "id": "y0wDwFQNaILF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "\n",
        "class BGForecastModel:\n",
        "    def __init__(self):\n",
        "        self.model = xgb.XGBRegressor(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=5,\n",
        "            objective='reg:squarederror'\n",
        "        )\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def prepare_features(self, df):\n",
        "        # Drop label and ID columns for scaling\n",
        "        feature_cols = [col for col in df.columns if col not in ['id', 'p_num', 'bg+1:00']]\n",
        "        return feature_cols\n",
        "\n",
        "    def fit(self, train_df):\n",
        "        feature_cols = self.prepare_features(train_df)\n",
        "        X = train_df[feature_cols]\n",
        "        y = train_df['bg+1:00']\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Train model\n",
        "        self.model.fit(X_scaled, y)\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        feature_cols = self.prepare_features(test_df)\n",
        "        X = test_df[feature_cols]\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "\n",
        "        # Return results with ID\n",
        "        results = pd.DataFrame({\n",
        "            'id': test_df['id'],\n",
        "            'bg+1:00': predictions\n",
        "        })\n",
        "        return results"
      ],
      "metadata": {
        "id": "N_JrDFy6aFyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}